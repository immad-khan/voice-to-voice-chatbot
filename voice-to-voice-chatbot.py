# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a_nnfYBteU45GzzJHJ9D4A2W9LtNNVz-
"""
// Walkthorugh
!pip install gradio openai-whisper groq gTTS unidecode
//TO HELL with your edits Shabaz!! THis is MYYY edit now. OMAR WAS HEREEREEEE MUHAHAHAHAHHAHA
import os
import gradio as gr
import whisper
from groq import Groq
from gtts import gTTS
import tempfile
import numpy as np
from unidecode import unidecode

os.environ["GROQ_API_KEY"] = "Add your own GROQ API key, Its very easy"

# Load Whisper model
whisper_model = whisper.load_model("base")

# Initialize Groq client
client = Groq(api_key=os.environ.get("GROQ_API_KEY"))

def voice_to_voice_chat(audio):
    """
    Process audio input, transcribe it, get LLM response, and convert response to audio.
    """
    try:
        # Check if audio input is None
        if audio is None:
            return "No audio input detected. Please record and submit again.", None

        # Handle audio input
        if isinstance(audio, np.ndarray):
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio:
                whisper.write(audio, temp_audio.name)
                audio_path = temp_audio.name
        else:
            audio_path = audio

        # Transcribe audio using Whisper
        transcription = whisper_model.transcribe(audio_path, fp16=False)
        user_text = transcription["text"].strip()

        if not user_text:
            return "No speech detected in the audio.", None

        # Get response from Groq LLM
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": user_text}],
            model="llama3-8b-8192",
        )
        response_text = chat_completion.choices[0].message.content

        # Clean the response text using unidecode and replace remaining non-ASCII characters
        clean_text = unidecode(response_text)
        clean_text = ''.join(char if ord(char) < 128 else ' ' for char in clean_text)

        if not clean_text or all(c == ' ' for c in clean_text):
            return "No valid text to convert to audio.", None

        # Convert cleaned text to audio using gTTS
        tts = gTTS(clean_text, lang="en")
        output_audio_path = tempfile.NamedTemporaryFile(suffix=".mp3", delete=False).name
        tts.save(output_audio_path)

        return clean_text, output_audio_path

    except Exception as e:
        return f"Error: {str(e)}", None
    finally:
        if isinstance(audio, np.ndarray) and 'audio_path' in locals():
            os.unlink(audio_path)

# Define Gradio interface
with gr.Blocks(title="Voice-to-Voice Chatbot") as interface:
    gr.Markdown("# Voice-to-Voice Chatbot")
    gr.Markdown("Speak into the microphone, and the bot will respond with audio!")

    with gr.Row():
        audio_input = gr.Audio(sources=["microphone"], type="filepath", label="Speak Here")
        submit_button = gr.Button("Submit")

    text_output = gr.Textbox(label="Bot Response Text")
    audio_output = gr.Audio(label="Bot Response Audio", type="filepath")

    submit_button.click(
        fn=voice_to_voice_chat,
        inputs=audio_input,
        outputs=[text_output, audio_output]
    )

# Launch Gradio interface
interface.launch(share=True)  # Use share=True for a public URL in Colab
